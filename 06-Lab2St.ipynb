{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1. Loading Dataset\n",
    "Load the `Prima Indians Onset of Diabates` dataset. It is a standard machine learning dataset available for free download from the UCI Machine Learning repository. It describes patient medical record data for Pima Indians and whether they had an onset of diabetes within five years. It is a binary classification problem (onset of diabetes as 1 or not as\n",
    "0)\n",
    "\n",
    "\n",
    "- NTP: Number of times pregnant.\n",
    "- PGC: Plasma glucose concentration a 2 hours in an oral glucose tolerance test. 3. Diastolic blood pressure (mm Hg).\n",
    "- TSFT: Triceps skin fold thickness (mm).\n",
    "- 2hSI: 2-Hour serum insulin (mu U/ml).\n",
    "- BMI: Body mass index.\n",
    "- DPF: Diabetes pedigree function.\n",
    "- Age: Age (years).\n",
    "- OnDiab: Class, onset of diabetes within five years.\n",
    "\n",
    "\n",
    "- Set the dataset columns names to `['NTP', 'PGC','DBP','TSFT','2hSI','BMI','DPF','Age','OnDiab']`.\n",
    "- Print the size of the data set.\n",
    "- Print the first 10 observations of your data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Data type and description for each attribute\n",
    "- Print the data type for each attribute using `dtypes` method of a pandas data frame\n",
    "- Descriptive statistics can give you great insight into the properties of each attribute. Often you can create more summaries than you have time to review. The `describe()` function on the Pandas DataFrame lists 8 statistical properties of each attribute. They are: Count, Mean, Standard Deviation, Minimum Value, 25th Percentile, 50th Percentile (Median), 75th Percentile, Maximum Value.\n",
    "- On classication problems you need to know how balanced the class values are. Highly imbalanced problems (a lot more observations for one class than another) are common and may need special handling in the data preparation stage of your project. You can quickly get an idea of the distribution of the `OnDiab` attribute in Pandas. Grup your data by `OnDiab` attribute and use the `size` method to count the number of different values of `class` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Draw the histogram of your data attributes.\n",
    "A fast way to get an idea of the distribution of each attribute is to look at histograms. Histograms\n",
    "group data into bins and provide you a count of the number of observations in each bin. From\n",
    "the shape of the bins you can quickly get a feeling for whether an attribute is Gaussian, skewed\n",
    "or even has an exponential distribution. It can also help you see possible outliers.\n",
    "\n",
    "- Use `hist()` method of pandas data frame to plot the histograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Running a Classifier\n",
    "- Separate your dataset into feature set `X` and target variable `y`. Your target variable is `OnDiab`. \n",
    "- Split your dataset into train and test datasets, keep the test dataset size as 0.25 using `test_size` parameter of `train_test_split`. Set the random seed top 7 using `random_state` parameter of `train_test_split`. Make a stratified split.\n",
    "- Train `KNearestNeighbor` classifer on your train dataset and print the score on the the test dataset. Set number of neighbors to 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5 : Grid Search\n",
    "- Import `GridSearchCV` from `sklearn.model_selection`\n",
    "- Split your data into train and test datasets\n",
    "- For `neighbors=1 to 30`, compute `GridSearchCV` for train dataset with kfold=10.\n",
    "- Print the best cross validation score \n",
    "- Print the best parameter\n",
    "- Print the test score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
